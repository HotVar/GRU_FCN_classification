{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('open/train_features.csv')\n",
    "label = pd.read_csv('open/train_labels.csv')\n",
    "display(data)\n",
    "data.iloc[:, 2:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(label)\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.ylim(0, 125)\n",
    "label['label'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = data['id'].unique()\n",
    "rnd_id = np.random.choice(unique_ids)\n",
    "rnd_data = data[data['id']==rnd_id]\n",
    "\n",
    "fig, axes = plt.subplots(6, 1, figsize=(10, 5))\n",
    "print(label[label['id']==rnd_id].iloc[0, 2])\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(rnd_data.iloc[:, 2+i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':.6f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self._list = []\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self._list.append(self.avg)\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "    \n",
    "def get_inout_seq(seq, len_seq, len_pred):\n",
    "    inout_seq = []\n",
    "    L = len(seq)\n",
    "    for i in range(0, L-len_pred, len_pred):\n",
    "        input_seq = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, batch_size, device):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=False, dropout=0.)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense1 = nn.Linear(hidden_size, output_size*2)\n",
    "        self.dense2 = nn.Linear(output_size*2, output_size)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        hidden = self.init_hidden()\n",
    "        input_ = input_.view(len(input_), self.batch_size, -1)\n",
    "        output, hidden = self.gru(input_, hidden)\n",
    "        output = self.relu(output[-1, :, :].squeeze())\n",
    "        output = self.dense1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.dense2(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=self.device)\n",
    "    \n",
    "\n",
    "class Exercise_dataset(Dataset):\n",
    "    def __init__(self, df, label, device):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "        self.device = device\n",
    "        self.unique_ids = self.df['id'].unique()\n",
    "        self.unique_labels = self.label['label'].unique()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.unique_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self.unique_ids)\n",
    "        id_ = self.unique_ids[idx]\n",
    "        \n",
    "        sample = dict()\n",
    "        sample['seq'] = torch.Tensor(self.df[self.df['id']==id_].iloc[:, 2:].values, device=self.device)\n",
    "#         sample['label'] = torch.Tensor(self.enc.transform([[idx]]), device=self.device)\n",
    "        sample['label'] = torch.Tensor([self.label[self.label['id']==id_].iloc[0, 1]], device=self.device)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "N_EPOCHS = 30\n",
    "VIS_FREQ = 1\n",
    "N_CLASSES = len(label['label'].unique())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "unique_ids = data['id'].unique()\n",
    "cv = KFold(n_splits=5,\n",
    "           random_state=42,\n",
    "           shuffle=True)\n",
    "\n",
    "for k, (train_id, valid_id) in enumerate(cv.split(unique_ids)):\n",
    "    print(f'Fold {k} ' + '='*50)\n",
    "    X_train = data[data['id'].isin(train_id)]\n",
    "    y_train = label[label['id'].isin(train_id)]\n",
    "    X_valid = data[data['id'].isin(valid_id)]\n",
    "    y_valid = label[label['id'].isin(valid_id)]\n",
    "    \n",
    "    train_dataset = Exercise_dataset(X_train, y_train, device)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    valid_dataset = Exercise_dataset(X_valid, y_valid, device)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "    model = GRU_classifier(input_size=6,\n",
    "                           hidden_size=4,\n",
    "                           num_layers=1,\n",
    "                           output_size=len(label['label'].unique()),\n",
    "                           batch_size=1,\n",
    "                           device=device)\n",
    "\n",
    "    loss_CE = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=1e-03, weight_decay=1e-02)\n",
    "    \n",
    "    loss_train = AverageMeter('loss_train', ':.6f')\n",
    "    loss_valid = AverageMeter('loss_valid', ':.6f')\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        for i, (train_sample, valid_sample) in enumerate(zip(train_dataloader, valid_dataloader)):\n",
    "            train_seq = train_sample['seq']\n",
    "            train_label = train_sample['label']\n",
    "            train_seq = train_seq.transpose(0, 1)\n",
    "            train_label = train_label.transpose(0, 1).squeeze(1).long()\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            \n",
    "            pred, hidden = model(train_seq)\n",
    "            \n",
    "            if pred.size(0)==N_CLASSES:\n",
    "                pred = pred.unsqueeze(0)\n",
    "#             if train_label.size(0)==1:\n",
    "#                 train_label = train_label.unsqueeze(0)\n",
    "                \n",
    "#             print(f'pred : {pred.size()}')\n",
    "#             print(f'label : {train_label.size()}')\n",
    "#             print(pred)\n",
    "#             print(train_label)\n",
    "            loss = loss_CE(pred, train_label)\n",
    "            loss_train.update(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                valid_seq = valid_sample['seq']\n",
    "                valid_label = valid_sample['label']\n",
    "                valid_seq = valid_seq.transpose(0, 1)\n",
    "                valid_label = valid_label.transpose(0, 1).squeeze(1).long()\n",
    "                \n",
    "                pred, hidden = model(valid_seq)\n",
    "                \n",
    "                if pred.size(0)==N_CLASSES:\n",
    "                    pred = pred.unsqueeze(0)\n",
    "                    \n",
    "                loss = loss_CE(pred, valid_label)\n",
    "                loss_valid.update(loss.item())\n",
    "        \n",
    "        if epoch % VIS_FREQ == 0:\n",
    "            print(f'Epoch[{epoch}] : {loss_train}, {loss_valid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(loss_train.avg_list, color='b', label='loss_train')\n",
    "    plt.plot(loss_valid.avg_list, color='r', label='loss_valid')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "show_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
